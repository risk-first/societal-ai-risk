---
title: Kill Switch
description: Fail-safe systems capable of shutting down or isolating AI processes if they exhibit dangerous behaviours.
sidebar_position: 3
list_image: /img/icons/control.svg
tags:
  - Control
  - Kill Switch
gemara:
  id: Kill-Switch
  title: Kill Switch
  objective: Implementing fail-safe mechanisms capable of shutting down or isolating AI processes if they exhibit dangerous behaviours.
  mitigates:
    - reference-id: loss-of-human-control
      reason: An explicit interruption capability can avert catastrophic errors or runaway behaviours
    - reference-id: superintelligence-with-malicious-intent
      reason: Implementing fail-safe mechanisms to neutralise dangerous AI weapons systems
---

<ControlIntro fm={frontMatter} />

## Examples
  
  - **Google DeepMind’s ‘Big Red Button’ concept** (2016), proposed as a method to interrupt a reinforcement learning AI without it learning to resist interruption.  
  
  - **Hardware Interrupts in Robotics:** Physical or software-based emergency stops that immediately terminate AI operation.  
